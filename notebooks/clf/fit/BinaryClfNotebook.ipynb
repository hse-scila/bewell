{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import importlib\n",
    "from itertools import chain, combinations, product\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'RandomForestClassifier': [\n",
    "    {\n",
    "     \"n_estimators\": [10, 50, 100], \"max_depth\": [None, 10, 50, 100]\n",
    "    }\n",
    "],\n",
    "'AdaBoostClassifier': [\n",
    "    {\n",
    "     \"algorithm\": [\"SAMME.R\"]\n",
    "    }\n",
    "],\n",
    "              \n",
    "'SVC': [\n",
    "    {\n",
    "        \"kernel\": [\"rbf\"]#, \"poly\", \"rbf\", \"sigmoid\"]\n",
    "    }\n",
    "],\n",
    "              \n",
    "'DecisionTreeClassifier': [\n",
    "    {\n",
    "     \"criterion\": [\"gini\", \"entropy\"], \"max_depth\": [None, 10, 50, 100]\n",
    "    }\n",
    "],\n",
    "              \n",
    "              }\n",
    "\n",
    "models = {\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"SVC\": SVC(),\n",
    "}\n",
    "\n",
    "\n",
    "def set_params( func, parameters ):\n",
    "    for parameter, value in parameters.items():\n",
    "        if hasattr(func, parameter):\n",
    "            setattr(func, parameter, value)\n",
    "    return func\n",
    "\n",
    "\n",
    "def powerset( iterable ):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))\n",
    "\n",
    "\n",
    "def eval_nestedCV( X, y, wb, step=1, verbose=0, method='', fsname='', funcname='Ridge', fout=None, fout_mean=None ):\n",
    "    grids = parameters[funcname]\n",
    "\n",
    "    wb = wb.lower()\n",
    "    sortedarg = np.asarray(y.argsort())\n",
    "    cv = []\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    y = np.where(y > 15 , 1, 0)\n",
    "    for i in range(5):\n",
    "        for j in range(2):\n",
    "            if j:\n",
    "                di = i * 2\n",
    "                ti = i * 2 + 1\n",
    "            else:\n",
    "                di = i * 2 + 1\n",
    "                ti = i * 2\n",
    "            dev = sortedarg[di::10]\n",
    "            test = sortedarg[ti::10]\n",
    "            train = np.setdiff1d(sortedarg, np.concatenate((dev, test)))\n",
    "            cv.append([train, dev, test])\n",
    "\n",
    "    f1_scores, roc_auc_scores = [], []\n",
    "    f1_scores_dev = []\n",
    "    test_target_samples, test_predictions = [], []\n",
    "\n",
    "    for i, [train, dev, test] in enumerate(cv):\n",
    "        best_params = {}\n",
    "\n",
    "        best_f1 = 0\n",
    "        print(i, 'CV fold..', flush=True)\n",
    "\n",
    "        for grid in grids:\n",
    "            keys = sorted(grid.keys())\n",
    "            for comb in product(*[val for k, val in sorted(grid.items())]):\n",
    "                model = set_params(deepcopy(models[funcname]), dict(zip(keys, comb)))\n",
    "                if verbose:\n",
    "                    print('Model:', funcname, 'params:', dict(zip(keys, comb)), 'est:', model)\n",
    "\n",
    "                fs = RFECV(\n",
    "                    model, \n",
    "                    cv=[[train, dev]], \n",
    "                    scoring=make_scorer(f1_score, greater_is_better=True, average=\"macro\"), \n",
    "                    step=step\n",
    "                )\n",
    "                fs.fit(X, y)\n",
    "                if verbose:\n",
    "                    print(fs.n_features_, flush=True)\n",
    "                f1_score_max = fs.grid_scores_.max()\n",
    "                print(\"f1_score_max\", f1_score_max, flush=True)\n",
    "\n",
    "                if best_f1 < f1_score_max:\n",
    "                    best_f1 = f1_score_max\n",
    "                    best_params = dict(zip(keys, comb))\n",
    "                    best_params['fs'] = fs\n",
    "                    best_params['fs_sup'] = int(sum(fs.get_support() == 1))\n",
    "\n",
    "        f1_scores_dev.append(best_f1)\n",
    "        print('Dev: ', best_f1, best_params, flush=True)\n",
    "        est = set_params(deepcopy(models[funcname]), best_params)\n",
    "        \n",
    "        est.fit(best_params['fs'].transform(X[train]), y[train])\n",
    "        testpred = est.predict(best_params['fs'].transform(X[test]))\n",
    "        \n",
    "\n",
    "        cur_f1_score = f1_score(y[test], testpred, average=\"macro\")\n",
    "        roc_auc_scores.append(roc_auc_score(y[test], testpred))\n",
    "        f1_scores.append(cur_f1_score)\n",
    "        test_target_samples.append(y[test])\n",
    "        test_predictions.append(testpred)\n",
    "\n",
    "    print('Dev final: ', round(np.mean(f1_scores_dev), 4), flush=True)\n",
    "    print('Test: ', [round(np.mean(x), 4) for x in [f1_scores, roc_auc_scores]], flush=True)\n",
    "    return test_target_samples, test_predictions\n",
    "\n",
    "\n",
    "wb = \"WHO\"\n",
    "funcname = \"AdaBoostClassifier\"  # Function\n",
    "method = \"RFECV\"  # F_ANOVA / RFECV\n",
    "\n",
    "assert funcname in set(models.keys())\n",
    "assert wb in {'WHO', 'Diener'}\n",
    "assert method in {'F_ANOVA', 'RFECV'}\n",
    "\n",
    "print('Function:', funcname)\n",
    "print('WB:', wb)\n",
    "print('method:', method)\n",
    "\n",
    "g1 = pd.read_csv('traincorr1.csv', index_col=[0, 1, 2])\n",
    "g2 = pd.read_csv('testcorr1.csv', index_col=[0, 1, 2])\n",
    "\n",
    "g = pd.concat([g1, g2])\n",
    "\n",
    "wbs = ['Diener', 'WHO']\n",
    "feats = ['clusters', 'words', 'Meta', 'AppCats', 'RuLIWC']\n",
    "indeces = [[0, 1], [0, 1], [0, 1, 2], [0, 1, 2], [0, 1, 2]]\n",
    "\n",
    "appdata1 = pd.read_csv('AppCatsBy3HoursNorm-1.csv', index_col=0)\n",
    "print(appdata1.shape)\n",
    "\n",
    "data = {}\n",
    "\n",
    "cldata = pd.read_csv('besth-clusters_' + wb + '.csv', index_col=[0, 1])\n",
    "data['clusters'] = g.join(cldata)[cldata.columns]\n",
    "data['AppCats'] = g.join(appdata1, lsuffix='mail')[appdata1.columns]\n",
    "\n",
    "wdf1 = pd.read_csv('RuLIWC-matrix-1year-traintest.csv', index_col=[0, 1, 2])\n",
    "data['RuLIWC'] = g.join(wdf1, rsuffix='APP_')[wdf1.columns]\n",
    "\n",
    "cols = g.dropna(axis=1).columns\n",
    "cols = cols[2:]\n",
    "cols = cols.drop(['MessNewest', 'MessOldest'])\n",
    "data['Behavior'] = g[cols]\n",
    "\n",
    "data['Words'] = pd.read_csv('words_selected.csv', index_col=[0, 1, 2])\n",
    "\n",
    "rat = {'who': 25., 'diener': 30.}\n",
    "metrs = ['MAE', 'Pearson', 'R-2']\n",
    "\n",
    "fs = ('clusters', 'Words')\n",
    "\n",
    "print('Nested CV, Feature set:')\n",
    "print(fs, flush=True)\n",
    "traindata = pd.concat([data[x] for x in fs], axis=1)\n",
    "print(traindata.shape, g['DF_' + wb.lower() + '_score'].shape, flush=True)\n",
    "print(funcname)\n",
    "labels = g.DF_who_score\n",
    "test_target_samples, test_predictions = eval_nestedCV(traindata, labels, wb, method=method, funcname=funcname, fsname=' + '.join(fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "scores = {i: [] for i in [\"roc_auc_score\", \"f1_micro\", \"f1_macro\", \"f1_weighted\", \"precision_score\", \"recall_score\"]}\n",
    "for i, j in zip(test_target_samples, test_predictions):\n",
    "    print(\"#\"*15)\n",
    "    print(confusion_matrix(i,j))\n",
    "    pr = precision_score(i,j)\n",
    "    print(\"precision_score\", pr )\n",
    "    scores[\"precision_score\"].append(pr)\n",
    "    rec = recall_score(i,j)\n",
    "    print(\"recall_score\", rec)\n",
    "    scores[\"recall_score\"].append(rec)\n",
    "    r = roc_auc_score(i, j)\n",
    "    print(\"roc_auc_score\", r )\n",
    "    scores[\"roc_auc_score\"].append(r)\n",
    "    f1_micro = f1_score(i, j, average=\"micro\")\n",
    "    print(\"f1_micro\", f1_micro)\n",
    "    scores[\"f1_micro\"].append(f1_micro)\n",
    "    f1_macro = f1_score(i, j, average=\"macro\")\n",
    "    print(\"f1_macro\", f1_macro)\n",
    "    scores[\"f1_macro\"].append(f1_macro)\n",
    "    f1_weighted = f1_score(i, j, average=\"weighted\")\n",
    "    print(\"f1_weighted\", f1_weighted)\n",
    "    scores[\"f1_weighted\"].append(f1_weighted)\n",
    "    print(\"#\"*15)\n",
    "\n",
    "for i, j in scores.items():\n",
    "    print(i, round(np.mean(j), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
