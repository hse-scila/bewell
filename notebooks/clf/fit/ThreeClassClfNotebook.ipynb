{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import importlib\n",
    "from itertools import chain, combinations, product\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'RandomForestClassifier': [\n",
    "    {\n",
    "     \"n_estimators\": [10, 50, 100], \"max_depth\": [None, 10, 50, 100]\n",
    "    }\n",
    "],\n",
    "'AdaBoostClassifier': [\n",
    "    {\n",
    "     \"algorithm\": [\"SAMME.R\"]\n",
    "    }\n",
    "],\n",
    "              \n",
    "'DecisionTreeClassifier': [\n",
    "    {\n",
    "     \"criterion\": [\"gini\", \"entropy\"], \"max_depth\": [None, 10, 50, 100]\n",
    "    }\n",
    "],\n",
    "\"LogisticRegression\": [{\"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}]\n",
    "}\n",
    "              \n",
    "\n",
    "models = {\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "    \"LogisticRegression\": LogisticRegression()\n",
    "}\n",
    "\n",
    "\n",
    "def set_params( func, parameters ):\n",
    "    for parameter, value in parameters.items():\n",
    "        if hasattr(func, parameter):\n",
    "            setattr(func, parameter, value)\n",
    "    return func\n",
    "\n",
    "\n",
    "def powerset( iterable ):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))\n",
    "\n",
    "\n",
    "def eval_nestedCV( X, y, wb, step=1, verbose=0, method='', fsname='', funcname='Ridge', fout=None, fout_mean=None ):\n",
    "    grids = parameters[funcname]\n",
    "\n",
    "    wb = wb.lower()\n",
    "    sortedarg = np.asarray(y.argsort())\n",
    "    cv = []\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    y = (y - 5)/ 25\n",
    "    \n",
    "    new_y = []\n",
    "    for i in y:\n",
    "        if i > 0.59:\n",
    "            new_y.append(2)\n",
    "        elif i <= 0.35:\n",
    "            new_y.append(0)\n",
    "        else:\n",
    "            new_y.append(1)\n",
    "\n",
    "    y = new_y\n",
    "\n",
    "    print(\"np.sum(y)\", Counter(list(y)))\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    for i in range(5):\n",
    "        for j in range(2):\n",
    "            if j:\n",
    "                di = i * 2\n",
    "                ti = i * 2 + 1\n",
    "            else:\n",
    "                di = i * 2 + 1\n",
    "                ti = i * 2\n",
    "            dev = sortedarg[di::10]\n",
    "            test = sortedarg[ti::10]\n",
    "            train = np.setdiff1d(sortedarg, np.concatenate((dev, test)))\n",
    "            cv.append([train, dev, test])\n",
    "\n",
    "    f1_scores = []\n",
    "    f1_scores_dev = []\n",
    "\n",
    "    for i, [train, dev, test] in enumerate(cv):\n",
    "        best_params = {}\n",
    "\n",
    "        best_f1 = 0\n",
    "        print(i, 'CV fold..', flush=True)\n",
    "\n",
    "        for grid in grids:\n",
    "            keys = sorted(grid.keys())\n",
    "            for comb in product(*[val for k, val in sorted(grid.items())]):\n",
    "                model = set_params(deepcopy(models[funcname]), dict(zip(keys, comb)))\n",
    "                if verbose:\n",
    "                    print('Model:', funcname, 'params:', dict(zip(keys, comb)), 'est:', model)\n",
    "\n",
    "                fs = RFECV(\n",
    "                    model, \n",
    "                    cv=[[train, dev]], \n",
    "                    scoring=make_scorer(f1_score, greater_is_better=True, average=\"macro\"), \n",
    "                    step=step\n",
    "                )\n",
    "                fs.fit(X, y)\n",
    "                if verbose:\n",
    "                    print(fs.n_features_, flush=True)\n",
    "                f1_score_max = fs.grid_scores_.max()\n",
    "                print(\"f1_score_max\", f1_score_max, flush=True)\n",
    "\n",
    "                if best_f1 < f1_score_max:\n",
    "                    best_f1 = f1_score_max\n",
    "                    best_params = dict(zip(keys, comb))\n",
    "                    best_params['fs'] = fs\n",
    "                    best_params['fs_sup'] = int(sum(fs.get_support() == 1))\n",
    "\n",
    "        f1_scores_dev.append(best_f1)\n",
    "        print('Dev: ', best_f1, best_params, flush=True)\n",
    "        est = set_params(deepcopy(models[funcname]), best_params)\n",
    "        \n",
    "        est.fit(best_params['fs'].transform(X[train]), y[train])\n",
    "        testpred = est.predict(best_params['fs'].transform(X[test]))\n",
    "\n",
    "        cur_f1_score = f1_score(y[test], testpred, average=\"macro\")\n",
    "        f1_scores.append(cur_f1_score)\n",
    "        \n",
    "\n",
    "        if fout is not None:\n",
    "            fout.write('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\\n'.format(method, wb, fsname, funcname, i + 1,\n",
    "                                                                                   best_f1, cur_f1_score,\n",
    "                                                                                   json.dumps({k: v for k, v in\n",
    "                                                                                               best_params.items() if\n",
    "                                                                                               k != 'fs'})))\n",
    "            fout.flush()\n",
    "\n",
    "    print('Dev final: ', round(np.mean(f1_scores_dev), 4), flush=True)\n",
    "    print('Test: ', [round(np.mean(x), 4) for x in [f1_scores]], flush=True)\n",
    "    if fout_mean is not None:\n",
    "        fout_mean.write('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\n'.format(method, wb, fsname, funcname,\n",
    "                                                                          round(np.mean(f1_scores_dev), 4),\n",
    "                                                                          round(np.mean(f1_scores), 4),\n",
    "                                                                          ))\n",
    "        fout_mean.flush()\n",
    "\n",
    "\n",
    "\n",
    "wb = \"WHO\"\n",
    "method = \"RFECV\"  # F_ANOVA / RFECV\n",
    "\n",
    "assert wb in {'WHO', 'Diener'}\n",
    "assert method in {'F_ANOVA', 'RFECV'}\n",
    "\n",
    "print('WB:', wb)\n",
    "print('method:', method)\n",
    "\n",
    "g1 = pd.read_csv('traincorr1.csv', index_col=[0, 1, 2])\n",
    "g2 = pd.read_csv('testcorr1.csv', index_col=[0, 1, 2])\n",
    "\n",
    "g = pd.concat([g1, g2])\n",
    "\n",
    "wbs = ['Diener', 'WHO']\n",
    "feats = ['clusters', 'words', 'Meta', 'AppCats', 'RuLIWC']\n",
    "indeces = [[0, 1], [0, 1], [0, 1, 2], [0, 1, 2], [0, 1, 2]]\n",
    "\n",
    "appdata1 = pd.read_csv('AppCatsBy3HoursNorm-1.csv', index_col=0)\n",
    "print(appdata1.shape)\n",
    "\n",
    "data = {}\n",
    "\n",
    "cldata = pd.read_csv('besth-clusters_' + wb + '.csv', index_col=[0, 1])\n",
    "data['clusters'] = g.join(cldata)[cldata.columns]\n",
    "data['AppCats'] = g.join(appdata1, lsuffix='mail')[appdata1.columns]\n",
    "\n",
    "wdf1 = pd.read_csv('RuLIWC-matrix-1year-traintest.csv', index_col=[0, 1, 2])\n",
    "data['RuLIWC'] = g.join(wdf1, rsuffix='APP_')[wdf1.columns]\n",
    "\n",
    "cols = g.dropna(axis=1).columns\n",
    "cols = cols[2:]\n",
    "cols = cols.drop(['MessNewest', 'MessOldest'])\n",
    "data['Behavior'] = g[cols]\n",
    "\n",
    "data['Words'] = pd.read_csv('words_selected.csv', index_col=[0, 1, 2])\n",
    "\n",
    "rat = {'who': 25., 'diener': 30.}\n",
    "metrs = ['MAE', 'Pearson', 'R-2']\n",
    "\n",
    "print('Feature sets:', data.keys())\n",
    "print('All combinations of features:', list(powerset(data.keys())))\n",
    "\n",
    "for funcname in models.keys():\n",
    "    try:\n",
    "        with open('./three_clf_devscores_max_correct_distr{0}_{1}_{2}.tsv'.format(funcname, wb, method), 'w',\n",
    "                  encoding='UTF8') as fout, \\\n",
    "                open('./three_clf_testscores_max_correct_distr{0}_{1}_{2}.tsv'.format(funcname, wb, method), 'w',\n",
    "                     encoding='UTF8') as fout_mean:\n",
    "            fout.write('method\\twb\\tfs\\tmodel\\tfold\\tf1_score_macro_dev\\tf1_score_test\\tparams\\n')\n",
    "            fout_mean.write('method\\twb\\tfs\\tmodel\\tf1_score_macro_dev\\tf1_score_test\\tparams\\n')\n",
    "\n",
    "            for fs in powerset(data.keys()):\n",
    "                if len(fs) == 0:\n",
    "                    continue\n",
    "                print('Nested CV, Feature set:')\n",
    "                print(fs, flush=True)\n",
    "                traindata = pd.concat([data[x] for x in fs], axis=1)\n",
    "                print(traindata.shape, g['DF_' + wb.lower() + '_score'].shape, flush=True)\n",
    "                print(funcname)\n",
    "                labels = g.DF_who_score\n",
    "                eval_nestedCV(traindata, labels, wb, method=method, funcname=funcname, fsname=' + '.join(fs), fout=fout,\n",
    "                              fout_mean=fout_mean)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
